{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hagarbarakat/Emotion_Detection/blob/master/Emotion_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCBghp7IMSck",
        "colab_type": "code",
        "outputId": "f32be301-e806-4692-c500-cd1e15561136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "import struct as st\n",
        "import os\n",
        "import scipy.io\n",
        "import math\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTY0Y3rrNTTx",
        "colab_type": "code",
        "outputId": "62a7533c-c9ce-4df0-dfad-a7c39f6785a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "Training_x = [] #training data list\n",
        "Training_y = [] #training labels list\n",
        "Validation_x = [] #validation data list\n",
        "Validation_y = []  #validation label list\n",
        "\n",
        "\n",
        "with open('fer2013.csv') as csvin:\n",
        "    data=csv.reader(csvin)\n",
        "    for row in data:\n",
        "      #row[-1] last item which indicates the usage of each image (training, public test, private test)\n",
        "        if row[-1] == 'Training' or row[-1] == 'PublicTest':                  #Training and Public test images are used for training\n",
        "            temp_list = []    \n",
        "            for pixel in row[1].split( ): \n",
        "                temp_list.append(int(pixel))\n",
        "            I = np.asarray(temp_list).reshape(48,48,1) #reshape data (48,48)\n",
        "            Training_y.append(int(row[0]))\n",
        "            #y_training=np.array(Training_y)\n",
        "            y_training=pd.get_dummies(Training_y) #hot encoding for training labels\n",
        "            Training_x.append(I.tolist())\n",
        "\n",
        "        if row[-1] == 'PrivateTest':           #Privates Test images are used for validation\n",
        "            temp_list = []\n",
        "            for pixel in row[1].split( ):\n",
        "                temp_list.append(int(pixel))\n",
        "            I = np.asarray(temp_list).reshape(48,48,1)\n",
        "            Validation_y.append(int(row[0]))\n",
        "            y_validation=pd.get_dummies(Validation_y) #hot encoding for validation labels\n",
        "            Validation_x.append(I.tolist())\n",
        "  \n",
        "print(np.shape(Training_x))\n",
        "print(np.shape(Training_y))\n",
        "print(np.shape(y_training))\n",
        "print(np.shape(Validation_x))\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32298, 48, 48, 1)\n",
            "(32298,)\n",
            "(32298, 7)\n",
            "(3589, 48, 48, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roq1GEuMOzYz",
        "colab_type": "code",
        "outputId": "cce8eb7a-7009-434c-b034-2f29481690ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "keras.optimizers.Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.optimizers.Adam at 0x7fee674d8b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "686h6nPlO-qr",
        "colab_type": "code",
        "outputId": "ed6fa5a7-cfdc-43f0-a11c-35232c1e0a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "#initialize cnn model\n",
        "model= Sequential()\n",
        "\n",
        "#Convolution\n",
        "model.add(Convolution2D(filters = 64, kernel_size = (2, 2),strides=(2,2), input_shape = (48, 48, 1), activation = 'sigmoid'))\n",
        "model.add(Dropout(0.35))\n",
        "model.add(Convolution2D(filters = 128, kernel_size = (2, 2),strides=(2,2), input_shape = (48, 48, 1), activation = 'sigmoid'))\n",
        "model.add(Dropout(0.35))\n",
        "model.add(Convolution2D(filters = 256, kernel_size = (2, 2),strides=(2,2), input_shape = (48, 48, 1), activation = 'sigmoid'))\n",
        "\n",
        "\n",
        "#Pooling\n",
        "\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides=(2,2)))\n",
        "\n",
        "\n",
        "\n",
        "#Flattening\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.35))\n",
        "\n",
        "#Fullconnection\n",
        "\n",
        "model.add(Dense(activation='sigmoid', units=256))\n",
        "\n",
        "model.add(Dropout(0.35))\n",
        "\n",
        "model.add(Dense(activation='softmax',units=7))\n",
        "\n",
        "\n",
        "#Compiling CNN\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 24, 24, 64)        320       \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 12, 12, 128)       32896     \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 6, 6, 256)         131328    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 256)               590080    \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 7)                 1799      \n",
            "=================================================================\n",
            "Total params: 756,423\n",
            "Trainable params: 756,423\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRVb3zsWPCrJ",
        "colab_type": "code",
        "outputId": "71931579-4a95-41c7-8e98-77c4314cb83b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the network\n",
        "model.fit(np.array(Training_x), y_training, epochs=50, validation_data=(np.array(Validation_x), y_validation),batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 32298 samples, validate on 3589 samples\n",
            "Epoch 1/50\n",
            "32298/32298 [==============================] - 9s 290us/step - loss: 1.8497 - acc: 0.2339 - val_loss: 1.8156 - val_acc: 0.2449\n",
            "Epoch 2/50\n",
            "32298/32298 [==============================] - 8s 252us/step - loss: 1.8170 - acc: 0.2507 - val_loss: 1.8163 - val_acc: 0.2449\n",
            "Epoch 3/50\n",
            "32298/32298 [==============================] - 8s 256us/step - loss: 1.8039 - acc: 0.2531 - val_loss: 1.7791 - val_acc: 0.2583\n",
            "Epoch 4/50\n",
            "32298/32298 [==============================] - 8s 260us/step - loss: 1.7656 - acc: 0.2765 - val_loss: 1.7540 - val_acc: 0.2800\n",
            "Epoch 5/50\n",
            "32298/32298 [==============================] - 8s 253us/step - loss: 1.7285 - acc: 0.3019 - val_loss: 1.6876 - val_acc: 0.3377\n",
            "Epoch 6/50\n",
            "32298/32298 [==============================] - 8s 253us/step - loss: 1.6889 - acc: 0.3232 - val_loss: 1.6453 - val_acc: 0.3533\n",
            "Epoch 7/50\n",
            "32298/32298 [==============================] - 8s 254us/step - loss: 1.6672 - acc: 0.3365 - val_loss: 1.6285 - val_acc: 0.3594\n",
            "Epoch 8/50\n",
            "32298/32298 [==============================] - 8s 254us/step - loss: 1.6415 - acc: 0.3496 - val_loss: 1.5881 - val_acc: 0.3828\n",
            "Epoch 9/50\n",
            "32298/32298 [==============================] - 8s 252us/step - loss: 1.6195 - acc: 0.3598 - val_loss: 1.5520 - val_acc: 0.3840\n",
            "Epoch 10/50\n",
            "32298/32298 [==============================] - 8s 253us/step - loss: 1.5894 - acc: 0.3783 - val_loss: 1.5294 - val_acc: 0.4001\n",
            "Epoch 11/50\n",
            "32298/32298 [==============================] - 8s 253us/step - loss: 1.5668 - acc: 0.3874 - val_loss: 1.5085 - val_acc: 0.4062\n",
            "Epoch 12/50\n",
            "32298/32298 [==============================] - 8s 254us/step - loss: 1.5489 - acc: 0.3976 - val_loss: 1.4904 - val_acc: 0.4149\n",
            "Epoch 13/50\n",
            "32298/32298 [==============================] - 8s 255us/step - loss: 1.5253 - acc: 0.4043 - val_loss: 1.4782 - val_acc: 0.4166\n",
            "Epoch 14/50\n",
            "32298/32298 [==============================] - 8s 254us/step - loss: 1.5086 - acc: 0.4168 - val_loss: 1.4454 - val_acc: 0.4302\n",
            "Epoch 15/50\n",
            "32298/32298 [==============================] - 8s 254us/step - loss: 1.4827 - acc: 0.4266 - val_loss: 1.4305 - val_acc: 0.4419\n",
            "Epoch 16/50\n",
            "32298/32298 [==============================] - 8s 253us/step - loss: 1.4678 - acc: 0.4306 - val_loss: 1.4206 - val_acc: 0.4397\n",
            "Epoch 17/50\n",
            "32298/32298 [==============================] - 8s 253us/step - loss: 1.4513 - acc: 0.4399 - val_loss: 1.4379 - val_acc: 0.4388\n",
            "Epoch 18/50\n",
            "32298/32298 [==============================] - 8s 253us/step - loss: 1.4271 - acc: 0.4509 - val_loss: 1.3966 - val_acc: 0.4514\n",
            "Epoch 19/50\n",
            "32298/32298 [==============================] - 8s 254us/step - loss: 1.4061 - acc: 0.4554 - val_loss: 1.3962 - val_acc: 0.4625\n",
            "Epoch 20/50\n",
            "32298/32298 [==============================] - 8s 255us/step - loss: 1.3899 - acc: 0.4665 - val_loss: 1.3857 - val_acc: 0.4575\n",
            "Epoch 21/50\n",
            "32298/32298 [==============================] - 8s 255us/step - loss: 1.3686 - acc: 0.4736 - val_loss: 1.3770 - val_acc: 0.4712\n",
            "Epoch 22/50\n",
            "32298/32298 [==============================] - 8s 254us/step - loss: 1.3501 - acc: 0.4803 - val_loss: 1.3588 - val_acc: 0.4767\n",
            "Epoch 23/50\n",
            "32298/32298 [==============================] - 8s 255us/step - loss: 1.3295 - acc: 0.4923 - val_loss: 1.3523 - val_acc: 0.4714\n",
            "Epoch 24/50\n",
            "32298/32298 [==============================] - 8s 253us/step - loss: 1.3170 - acc: 0.5011 - val_loss: 1.3532 - val_acc: 0.4748\n",
            "Epoch 25/50\n",
            "32298/32298 [==============================] - 8s 252us/step - loss: 1.2899 - acc: 0.5104 - val_loss: 1.3465 - val_acc: 0.4812\n",
            "Epoch 26/50\n",
            "32298/32298 [==============================] - 8s 258us/step - loss: 1.2738 - acc: 0.5173 - val_loss: 1.3334 - val_acc: 0.4826\n",
            "Epoch 27/50\n",
            "32298/32298 [==============================] - 8s 253us/step - loss: 1.2627 - acc: 0.5183 - val_loss: 1.3365 - val_acc: 0.4876\n",
            "Epoch 28/50\n",
            "32298/32298 [==============================] - 8s 253us/step - loss: 1.2372 - acc: 0.5314 - val_loss: 1.3296 - val_acc: 0.4887\n",
            "Epoch 29/50\n",
            "32298/32298 [==============================] - 8s 255us/step - loss: 1.2210 - acc: 0.5374 - val_loss: 1.3298 - val_acc: 0.4948\n",
            "Epoch 30/50\n",
            "32298/32298 [==============================] - 8s 256us/step - loss: 1.2055 - acc: 0.5453 - val_loss: 1.3342 - val_acc: 0.4921\n",
            "Epoch 31/50\n",
            "32298/32298 [==============================] - 8s 255us/step - loss: 1.1927 - acc: 0.5539 - val_loss: 1.3275 - val_acc: 0.4868\n",
            "Epoch 32/50\n",
            "32298/32298 [==============================] - 8s 254us/step - loss: 1.1710 - acc: 0.5574 - val_loss: 1.3184 - val_acc: 0.5010\n",
            "Epoch 33/50\n",
            "32298/32298 [==============================] - 8s 254us/step - loss: 1.1572 - acc: 0.5666 - val_loss: 1.3347 - val_acc: 0.4923\n",
            "Epoch 34/50\n",
            "32298/32298 [==============================] - 8s 252us/step - loss: 1.1362 - acc: 0.5718 - val_loss: 1.3077 - val_acc: 0.4987\n",
            "Epoch 35/50\n",
            "32298/32298 [==============================] - 8s 250us/step - loss: 1.1240 - acc: 0.5767 - val_loss: 1.3156 - val_acc: 0.4909\n",
            "Epoch 36/50\n",
            "32298/32298 [==============================] - 8s 252us/step - loss: 1.1114 - acc: 0.5816 - val_loss: 1.3056 - val_acc: 0.4996\n",
            "Epoch 37/50\n",
            "32298/32298 [==============================] - 8s 252us/step - loss: 1.0908 - acc: 0.5923 - val_loss: 1.3116 - val_acc: 0.4962\n",
            "Epoch 38/50\n",
            "32298/32298 [==============================] - 8s 253us/step - loss: 1.0810 - acc: 0.5975 - val_loss: 1.3111 - val_acc: 0.5043\n",
            "Epoch 39/50\n",
            "32298/32298 [==============================] - 8s 252us/step - loss: 1.0712 - acc: 0.5994 - val_loss: 1.3087 - val_acc: 0.5046\n",
            "Epoch 40/50\n",
            "32298/32298 [==============================] - 8s 252us/step - loss: 1.0589 - acc: 0.6058 - val_loss: 1.3121 - val_acc: 0.5079\n",
            "Epoch 41/50\n",
            "32298/32298 [==============================] - 8s 255us/step - loss: 1.0391 - acc: 0.6097 - val_loss: 1.3225 - val_acc: 0.5088\n",
            "Epoch 42/50\n",
            "32298/32298 [==============================] - 8s 261us/step - loss: 1.0415 - acc: 0.6094 - val_loss: 1.3021 - val_acc: 0.5107\n",
            "Epoch 43/50\n",
            "32298/32298 [==============================] - 8s 252us/step - loss: 1.0244 - acc: 0.6167 - val_loss: 1.3104 - val_acc: 0.5130\n",
            "Epoch 44/50\n",
            "32298/32298 [==============================] - 8s 255us/step - loss: 1.0177 - acc: 0.6171 - val_loss: 1.3117 - val_acc: 0.5071\n",
            "Epoch 45/50\n",
            "32298/32298 [==============================] - 8s 253us/step - loss: 0.9987 - acc: 0.6293 - val_loss: 1.3258 - val_acc: 0.5096\n",
            "Epoch 46/50\n",
            "32298/32298 [==============================] - 8s 253us/step - loss: 0.9932 - acc: 0.6302 - val_loss: 1.3189 - val_acc: 0.5104\n",
            "Epoch 47/50\n",
            "32298/32298 [==============================] - 8s 254us/step - loss: 0.9795 - acc: 0.6315 - val_loss: 1.3304 - val_acc: 0.5124\n",
            "Epoch 48/50\n",
            "32298/32298 [==============================] - 8s 254us/step - loss: 0.9650 - acc: 0.6404 - val_loss: 1.3162 - val_acc: 0.5118\n",
            "Epoch 49/50\n",
            "32298/32298 [==============================] - 8s 256us/step - loss: 0.9603 - acc: 0.6418 - val_loss: 1.3252 - val_acc: 0.5091\n",
            "Epoch 50/50\n",
            "32298/32298 [==============================] - 8s 253us/step - loss: 0.9479 - acc: 0.6482 - val_loss: 1.3098 - val_acc: 0.5146\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fec7ede3828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}